{"meta":{"title":"huzai9527's personal blog","subtitle":null,"description":null,"author":"John Doe","url":"http://yoursite.com"},"pages":[{"title":"Tags","date":"2018-11-11T05:38:56.590Z","updated":"2018-11-11T05:38:56.590Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"c++指针问题","slug":"c-指针问题","date":"2018-11-19T08:27:20.000Z","updated":"2018-11-19T09:42:52.179Z","comments":true,"path":"2018/11/19/c-指针问题/","link":"","permalink":"http://yoursite.com/2018/11/19/c-指针问题/","excerpt":"","text":"指针究竟是什么 指针是一类特殊的变量，他保存的不是一般数据的值，而是程序中另一对象在内存中的地址我们先通过一个小程序看一看指针如何工作1234567891011#include &lt;iostream&gt;using namespace std;int main()&#123; int n = 123,m = 456; int *p = &amp;n; cout&lt;&lt;\"&amp;n:\"&lt;&lt;&amp;n&lt;&lt;endl; cout&lt;&lt;\"&amp;p:\"&lt;&lt;&amp;p&lt;&lt;endl; cout&lt;&lt;\" p:\"&lt;&lt;p&lt;&lt;endl; cout&lt;&lt;\"*p:\"&lt;&lt;*p&lt;&lt;endl; return 0;&#125; 从运行结果可以看出下面几点： p本身是有一个地址的且地址为 &amp;p p的值是另一个变量n的地址 &amp;n *p所表示的意思是地址为 p 的内存中所存的值 n 即本段程序中共涉及到2个地址，一个是 n 的地址，一个是 p 的地址,我们用一张图来表示他们的关系指针的初始化 被具有相同类型的对象初始化 12int i = 10;int *p = &amp;i; 由另一个同一类型的指针初始化,这时两个指针指向同一地址空间 1int *p1 = p; 通过直接分配内存地址得到初值 1int *p2 = new int; 指针也可以没有类型，通用指针的定义,这样的指针可以指向任一对象 1void *p3 指针的运算符定义指针的目的事通过指针变量间接的访问变量 *:取指针值运算符。通过指针所指内存单元的地址间接的访问对应的存储单元。若指针变量p指向变量a，则 *p的运算结果为变量a的值 &amp;:取地址运算符。返回变量对应的存储单元地址，若a为int变量，p为int型指针变量，则 p = &amp;a表示将a的存储单元地址赋给p。用一个程序验证一下： 12345678910111213#include &lt;iostream&gt;using namespace std;int main()&#123; int a = 100; int *p,*p1,*q; p = &amp;a; p1 = p; q = NULL; cout&lt;&lt;\"a=\"&lt;&lt;a&lt;&lt;\",\"&lt;&lt;\"*p=\"&lt;&lt;*p&lt;&lt;\",\"&lt;&lt;\"p=\"&lt;&lt;p&lt;&lt;endl; *p1 = 200; cout&lt;&lt;\"a=\"&lt;&lt;a&lt;&lt;\",\"&lt;&lt;\"*p=\"&lt;&lt;*p&lt;&lt;\",\"&lt;&lt;\"p=\"&lt;&lt;p&lt;&lt;endl; cout&lt;&lt;\"*p1=\"&lt;&lt;*p1&lt;&lt;\",\"&lt;&lt;\"p1=\"&lt;&lt;p1&lt;&lt;endl;&#125; 运行结果 指针与数组的关系 数组名和指针在引用数组元素和取他们的地址方面可以相互转换，但两者有一个重要的不同点 数组是在定义时就分配好内存空间的，因此数组名是一个地址常量，在程序中不能将数组名作为变量为其赋值，而指针是一个变量，可以多次赋值我们通过一个程序看一下他们的关系 1234567891011121314#include &lt;iostream&gt;using namespace std;int main()&#123;int a[10]=&#123;1,2,3,4,5,6,7,8,9,10&#125;;int *pa = a;int i = 3;cout&lt;&lt;\"a[i] :\"&lt;&lt;a[i]&lt;&lt;endl;cout&lt;&lt;\"*(pa+i):\"&lt;&lt;*(pa+i)&lt;&lt;endl;cout&lt;&lt;\"*(a+i) :\"&lt;&lt;*(a+i)&lt;&lt;endl;cout&lt;&lt;\"&amp;a[i] :\"&lt;&lt;&amp;a[i]&lt;&lt;endl;cout&lt;&lt;\"a+i :\"&lt;&lt;a+i&lt;&lt;endl;cout&lt;&lt;\"pa+i :\"&lt;&lt;pa+i&lt;&lt;endl; &#125; 运行结果","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"http://yoursite.com/tags/c/"}]},{"title":"scrapy构建自己的ip代理池","slug":"scrapy构建自己的ip代理池","date":"2018-11-18T09:33:13.000Z","updated":"2018-11-19T08:15:02.296Z","comments":true,"path":"2018/11/18/scrapy构建自己的ip代理池/","link":"","permalink":"http://yoursite.com/2018/11/18/scrapy构建自己的ip代理池/","excerpt":"","text":"用scrapy爬取可用的代理分析免费代理网站的结构 我爬取了三个字段：IP、port、type分析要爬取的数据，编写items.py 因此在items.py中，建立相应的字段1234567import scrapyclass IproxyItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() ip = scrapy.Field() type = scrapy.Field() port = scrapy.Field() 爬取所有的免费ip 在spider目录下，创建IpSpider.py12345678910111213import scrapyimport Iproxy.itemsclass IpSpider(scrapy.Spider): name = 'IpSpider' allowed_domains = ['xicidaili.com'] start_urls = ['http://www.xicidaili.com/'] def parse(self, response): item = Iproxy.items.IproxyItem() item['ip'] = response.css('tr td:nth-child(2)::text').extract() item['port'] = response.css('tr td:nth-child(3)::text').extract() item['type'] = response.css('tr td:nth-child(6) ::text').extract() yield item 检测是否可用，如果可用则存入数据库 因为是免费的ip，所以我们有必要检测一下他是否可用，对于可用的就存入数据库，反之则丢弃 检测处理数据在pipeline.py中编写 检测原理，通过代理访问百度，如果能够访问，则说明可用1234567891011121314151617181920212223242526272829303132333435363738394041# -*- coding: utf-8 -*-# Define your item pipelines here## Don't forget to add your pipeline to the ITEM_PIPELINES setting# See: https://doc.scrapy.org/en/latest/topics/item-pipeline.htmlimport pymysqlimport requestsclass IproxyPipeline(object): def process_item(self, item, spider): print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@') db = pymysql.connect(\"localhost\", \"root\", \"168168\", \"spider\") cursor = db.cursor() for i in range(1, len(item['ip'])): ip = item['ip'][i] + ':' + item['port'][i] try: if self.proxyIpCheck(ip) is False: print('此ip：'+ip+\"不能用\") continue else: print('此ip：'+ip+'可用，存入数据库！') sql = 'insert into proxyIp value (\"%s\")' % (ip) cursor.execute(sql) db.commit() except: db.rollback() db.close() return item def proxyIpCheck(self, ip): proxies = &#123;'http': 'http://' + ip, 'https': 'https://' + ip&#125; try: r = requests.get('https://www.baidu.com/', proxies=proxies, timeout=1) if (r.status_code == 200): return True else: return False except: return False 运行情况 可以看出还是有好多ip不能用的 可用的存在数据库","categories":[],"tags":[{"name":"python scrapy 爬虫","slug":"python-scrapy-爬虫","permalink":"http://yoursite.com/tags/python-scrapy-爬虫/"}]},{"title":"python爬取最新更新的小说并发送到你的邮箱","slug":"python爬取最新更新的小说并发送到你的邮箱","date":"2018-11-17T07:07:29.000Z","updated":"2018-11-17T08:30:03.635Z","comments":true,"path":"2018/11/17/python爬取最新更新的小说并发送到你的邮箱/","link":"","permalink":"http://yoursite.com/2018/11/17/python爬取最新更新的小说并发送到你的邮箱/","excerpt":"","text":"数据获取—Spider()找目标网站，该网站是你看小说的网站，分析该网站的结构方便你对内容的抓取 这里我获取最新章节的时间、标题以及标题的连接 这里获取内容 编写spider方法，确定他的返回值，这里我返回的是一个list，包括更新的时间、标题、内容 方法中需要导入的包 requests bs4 re 12345678910111213141516171819202122def spider(): list = [] response = requests.get('https://www.xbiquge6.com/13_13134/') response.encoding = ('utf-8') html = response.text html = BeautifulSoup(html, 'html.parser') time = html.select('div#info p:nth-of-type(3)').__getitem__(0).text[5:] title = html.select('div#info p:nth-of-type(4) a[href]').__getitem__(0).text href = html.select('div#info p:nth-of-type(4) a[href]').__getitem__(0) # print(title) pattern = re.compile(r'href=\"(.+?)\"') href = re.findall(pattern, href.__str__()).__getitem__(0) href = \"https://www.xbiquge6.com\" + href response = requests.get(href) response.encoding = ('utf-8') html = BeautifulSoup(response.text, 'html.parser') content = html.select('div#content') # print(content) list.append(title) list.append(content) list.append(time) return list 邮件发送—smtp()首先先在你的邮箱中设置打开smtp服务比如我的QQ邮箱，先进入邮箱-&gt;点击设置-&gt;点击账户-&gt;下滑找到smtp服务-&gt;点击开启服务-&gt;生成授权码（就是你在smtp方法中用到的password）![PCO_6AO93%@2W$B}GFGHI0 (1).png 编写smtp方法，向我的邮箱发送小说，确定返回值是bool类型，成功为True，失败为False12345678910111213141516def mail(): list = spider(); ret = True try: mail_msg = list.__getitem__(1).__str__() msg = MIMEText(mail_msg, 'html', 'utf-8') msg['From'] = formataddr(['huzai', my_sender]) msg['To'] = formataddr(['huzai', receiver]) msg['Subject'] = list.__getitem__(0) server = smtplib.SMTP_SSL('smtp.qq.com', 465) server.login(my_sender, my_pwd) server.sendmail(my_sender, [receiver], msg.as_string()) server.quit() except Exception: ret = False return ret 上传脚本到服务器使用xftp将写好的smtp.py上传到你的云服务器上直接拖进去就行 这里注意保证你的服务器上的python版本和你本机一致，且需要的包已经安装 如果你的服务器上的版本是2.*的可以运行下面代码安装python3123sudo apt-get remove pythonsudo apt-get install python3sudo apt autoremove 用xshell进入服务器试着运行 在服务器端设置定时执行确保你安装了crontab（ubuntu默认安装）cron命名解析：执行的时间 + 执行的用户 + 执行的命令 查看原有的cron1cat /etc/crontab 编辑你的程序1sudo nano /etc/crontab 编写你的命令，每天14:58给我发送邮件，这里根据你看的小说的更新时间设置，一天几更在大约什么时间等等158 14 * * * root python3 smtp.py 编辑好了再次查看cron是否已经写入，我这里已经写入重启crontab服务1service cron restart 静静的等待14:58的到来，查看邮箱 邮件收到了最新更新的哦","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"github+hexo搭建个人博客","slug":"github-hexo搭建个人博客","date":"2018-11-11T09:46:19.000Z","updated":"2018-11-13T12:08:27.276Z","comments":true,"path":"2018/11/11/github-hexo搭建个人博客/","link":"","permalink":"http://yoursite.com/2018/11/11/github-hexo搭建个人博客/","excerpt":"","text":"1.创建的项目名默认为 用户名.github.io,创建时点击生成readme文件，方便后面添加说明 2.在本地创建一个文件夹，我是在E盘创建的blog，推荐用vscode作为编辑器，在编辑器里面打开文件夹，打开Terminer 3.使用hexo初始化文件夹，这一步会产生很多的hexo配置文件，我们先不管，先跑起来 4.运行hexo server打开服务，看看本地能不能显示运行后访问url，如果看到如图就成功了 5.配置文件中填写git的配置信息，按照如下格式填写 6.打开文件夹，右键git bash here 7.输入cd ~/.ssh，进入ssh文件夹 8.配置git中的用户名和邮箱 9.生成ssh密钥 10.在github的项目中加入密钥 11.测试密钥链接是否成功 12.测试成功后再再编辑器中运行hexo clean hexo g hexo d 这样就算上传成功 13.访问你的博客，看到之前再本地运行的界面，就行了","categories":[],"tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-11-10T13:00:35.376Z","updated":"2018-11-10T13:00:35.376Z","comments":true,"path":"2018/11/10/hello-world/","link":"","permalink":"http://yoursite.com/2018/11/10/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}